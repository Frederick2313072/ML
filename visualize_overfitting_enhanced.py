"""
å¢žå¼ºç‰ˆï¼šå¯è§†åŒ–AdaBoostè¿‡æ‹Ÿåˆè¿‡ç¨‹ + è¯¦ç»†è®­ç»ƒç›‘æŽ§
ç»“åˆ BoostMonitor æä¾›æ›´æ·±å…¥çš„è®­ç»ƒåŠ¨æ€åˆ†æž
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from src.utils import prepare_data
from src.evaluation import visualize_overfitting_process
from src.monitor import BoostMonitor
from src.patch import AdaBoostClfWithMonitor


def visualize_detailed_training(monitor, n_estimators, save_path=None):
    """
    ä½¿ç”¨ BoostMonitor æ•°æ®ç”Ÿæˆè¯¦ç»†çš„è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–
    
    å‚è€ƒ docs/monitor.md ä¸­çš„æ•°æ®ç»“æž„
    
    Parameters
    ----------
    monitor : BoostMonitor
        è®­ç»ƒç›‘æŽ§å¯¹è±¡
    n_estimators : int
        å¼±å­¦ä¹ å™¨æ•°é‡
    save_path : str, optional
        ä¿å­˜è·¯å¾„
    """
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    fig.suptitle(f'Detailed Training Analysis (n_estimators={n_estimators})', 
                 fontsize=16, fontweight='bold')
    
    rounds = list(range(1, len(monitor.error_history) + 1))
    
    # ========== 1. é”™è¯¯çŽ‡æ¼”åŒ– ==========
    ax1 = axes[0, 0]
    ax1.plot(rounds, monitor.error_history, 'b-', linewidth=2, label='Weighted Error')
    if len(monitor.error_without_weight_history) == len(rounds):
        ax1.plot(rounds, monitor.error_without_weight_history, 'r--', 
                linewidth=2, label='Unweighted Error', alpha=0.7)
    ax1.set_xlabel('Boosting Round', fontsize=12)
    ax1.set_ylabel('Error Rate', fontsize=12)
    ax1.set_title('Error Rate Evolution', fontsize=14, fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # ========== 2. Alpha ç³»æ•°æ¼”åŒ– ==========
    ax2 = axes[0, 1]
    ax2.plot(rounds, monitor.alpha_history, 'g-', linewidth=2, marker='o', 
            markersize=4, markevery=max(1, len(rounds)//20))
    ax2.set_xlabel('Boosting Round', fontsize=12)
    ax2.set_ylabel('Alpha (Weak Learner Weight)', fontsize=12)
    ax2.set_title('Alpha Coefficient Evolution', fontsize=14, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    
    # æ ‡æ³¨å¹³å‡å€¼
    avg_alpha = np.mean(monitor.alpha_history)
    ax2.axhline(y=avg_alpha, color='orange', linestyle='--', 
               label=f'Mean={avg_alpha:.3f}', alpha=0.7)
    ax2.legend()
    
    # ========== 3. è®­ç»ƒ vs éªŒè¯å‡†ç¡®çŽ‡ ==========
    ax3 = axes[0, 2]
    if len(monitor.acc_on_train_data) > 0:
        ax3.plot(rounds, monitor.acc_on_train_data, 'b-', linewidth=2, 
                label='Train Accuracy', marker='o', markersize=4,
                markevery=max(1, len(rounds)//20))
    if len(monitor.val_acc_history) > 0:
        ax3.plot(rounds, monitor.val_acc_history, 'r-', linewidth=2, 
                label='Val Accuracy', marker='s', markersize=4,
                markevery=max(1, len(rounds)//20))
    ax3.set_xlabel('Boosting Round', fontsize=12)
    ax3.set_ylabel('Accuracy', fontsize=12)
    ax3.set_title('Training vs Validation Accuracy', fontsize=14, fontweight='bold')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # ========== 4. å™ªå£°æ ·æœ¬ vs å¹²å‡€æ ·æœ¬æƒé‡ ==========
    ax4 = axes[1, 0]
    if monitor.is_data_noisy and len(monitor.noisy_weight_history) > 0:
        ax4.plot(rounds, monitor.noisy_weight_history, 'r-', linewidth=2, 
                label='Noisy Samples Weight', marker='o', markersize=4,
                markevery=max(1, len(rounds)//20))
        ax4.plot(rounds, monitor.clean_weight_history, 'g-', linewidth=2, 
                label='Clean Samples Weight', marker='s', markersize=4,
                markevery=max(1, len(rounds)//20))
        ax4.set_xlabel('Boosting Round', fontsize=12)
        ax4.set_ylabel('Total Weight', fontsize=12)
        ax4.set_title('Noisy vs Clean Sample Weights', fontsize=14, fontweight='bold')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        # æ ‡æ³¨åˆå§‹çŠ¶æ€ï¼ˆåº”è¯¥æŽ¥è¿‘ 0.5ï¼‰
        ax4.axhline(y=0.5, color='black', linestyle='--', alpha=0.3, linewidth=1)
    else:
        ax4.text(0.5, 0.5, 'Noise Analysis\nNot Available\n(Clean Data)', 
                ha='center', va='center', fontsize=14, color='gray')
        ax4.set_xticks([])
        ax4.set_yticks([])
    
    # ========== 5. F1 åˆ†æ•°æ¼”åŒ– ==========
    ax5 = axes[1, 1]
    if len(monitor.f1_on_training_data) > 0:
        ax5.plot(rounds, monitor.f1_on_training_data, 'b-', linewidth=2, 
                label='Train F1', marker='o', markersize=4,
                markevery=max(1, len(rounds)//20))
    if len(monitor.val_f1_history) > 0:
        ax5.plot(rounds, monitor.val_f1_history, 'r-', linewidth=2, 
                label='Val F1', marker='s', markersize=4,
                markevery=max(1, len(rounds)//20))
    ax5.set_xlabel('Boosting Round', fontsize=12)
    ax5.set_ylabel('F1 Score', fontsize=12)
    ax5.set_title('F1 Score Evolution', fontsize=14, fontweight='bold')
    ax5.legend()
    ax5.grid(True, alpha=0.3)
    
    # ========== 6. æ ·æœ¬æƒé‡åˆ†å¸ƒå˜åŒ– ==========
    ax6 = axes[1, 2]
    if len(monitor.sample_weights_history) > 0:
        # é€‰æ‹©å‡ ä¸ªå…³é”®è½®æ¬¡å±•ç¤º
        key_rounds = [0, len(rounds)//3, len(rounds)*2//3, len(rounds)-1]
        positions = []
        data_to_plot = []
        labels = []
        
        for i, idx in enumerate(key_rounds):
            if idx < len(monitor.sample_weights_history):
                positions.append(i + 1)
                data_to_plot.append(monitor.sample_weights_history[idx])
                labels.append(f'Round {idx+1}')
        
        # ç®±åž‹å›¾
        bp = ax6.boxplot(data_to_plot, positions=positions, widths=0.6, patch_artist=True,
                        labels=labels)
        
        # ç¾ŽåŒ–ç®±åž‹å›¾
        for patch in bp['boxes']:
            patch.set_facecolor('lightblue')
            patch.set_alpha(0.7)
        
        ax6.set_ylabel('Sample Weight', fontsize=12)
        ax6.set_title('Sample Weight Distribution', fontsize=14, fontweight='bold')
        ax6.grid(True, alpha=0.3, axis='y')
        ax6.tick_params(axis='x', rotation=15)
    else:
        ax6.text(0.5, 0.5, 'Sample Weight\nDistribution\nNot Available', 
                ha='center', va='center', fontsize=14, color='gray')
        ax6.set_xticks([])
        ax6.set_yticks([])
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"Detailed training visualization saved to: {save_path}")
    else:
        plt.show()
    
    plt.close()


def main():
    """ä¸»å‡½æ•°ï¼šå¢žå¼ºç‰ˆè¿‡æ‹Ÿåˆå¯è§†åŒ– + è¯¦ç»†è®­ç»ƒç›‘æŽ§"""
    
    print("\n" + "â–ˆ" * 60)
    print("AdaBoost Enhanced Visualization".center(60))
    print("Overfitting Analysis + Training Monitoring".center(60))
    print("â–ˆ" * 60)
    
    # ========== 1. é€‰æ‹©æ•°æ®ç±»åž‹ ==========
    print("\né€‰æ‹©æ•°æ®ç±»åž‹:")
    print("1. å¹²å‡€æ•°æ®ï¼ˆæ— å™ªå£°ï¼‰")
    print("2. å«å™ªå£°æ•°æ®ï¼ˆ5%å™ªå£°ï¼‰â­ æŽ¨è")
    print("3. å«å™ªå£°æ•°æ®ï¼ˆ10%å™ªå£°ï¼‰")
    
    choice = 2  # é»˜è®¤ä½¿ç”¨é€‰é¡¹2
    
    if choice == 1:
        noise_ratio = 0
        data_type = "Clean Data"
    elif choice == 2:
        noise_ratio = 0.05
        data_type = "5% Noisy Data"
    else:
        noise_ratio = 0.10
        data_type = "10% Noisy Data"
    
    print(f"\nä½¿ç”¨: {data_type}")
    print("-" * 60)
    
    # ========== 2. å‡†å¤‡æ•°æ® ==========
    print("\nå‡†å¤‡æ•°æ®...")
    X_train, X_test, y_train, y_test, noise_idx, clean_idx = prepare_data(
        noise_ratio=noise_ratio
    )
    
    print(f"è®­ç»ƒé›†å¤§å°: {len(X_train)}")
    print(f"æµ‹è¯•é›†å¤§å°: {len(X_test)}")
    if noise_ratio > 0:
        print(f"å™ªå£°æ ·æœ¬: {len(noise_idx)} ({len(noise_idx)/len(X_train)*100:.1f}%)")
        print(f"å¹²å‡€æ ·æœ¬: {len(clean_idx)} ({len(clean_idx)/len(X_train)*100:.1f}%)")
    
    # ========== 3. é€‰æ‹©é…ç½® ==========
    print("\n" + "=" * 60)
    print("Configuration".center(60))
    print("=" * 60)
    
    # å¿«é€Ÿé…ç½®
    config = {
        "base_estimator": DecisionTreeClassifier(max_depth=1),
        "n_estimators_list": [1, 5, 10, 20, 30, 40, 50, 75, 100],
        "learning_rate": 0.5,
        "random_state": 42,
    }
    
    print(f"Base Estimator: Decision Tree (max_depth={config['base_estimator'].max_depth})")
    print(f"Test Points: {len(config['n_estimators_list'])}")
    print(f"Estimators Range: {config['n_estimators_list'][0]} - {config['n_estimators_list'][-1]}")
    print(f"Learning Rate: {config['learning_rate']}")
    
    # ========== 4. ç¬¬ä¸€é˜¶æ®µï¼šè¿‡æ‹Ÿåˆå¯è§†åŒ– ==========
    print("\n" + "=" * 60)
    print("Phase 1: Overfitting Analysis".center(60))
    print("=" * 60)
    
    results = visualize_overfitting_process(
        X_train,
        y_train,
        X_test,
        y_test,
        base_estimator=config["base_estimator"],
        n_estimators_list=config["n_estimators_list"],
        learning_rate=config["learning_rate"],
        random_state=config["random_state"],
        save_path=None,
    )
    
    # æ‰¾åˆ°æœ€ä½³é…ç½®
    best_idx = results["test_accuracy"].index(max(results["test_accuracy"]))
    best_n = results["n_estimators"][best_idx]
    best_test_acc = results["test_accuracy"][best_idx]
    
    print(f"\nâœ“ Best Configuration Found:")
    print(f"   - Number of Estimators: {best_n}")
    print(f"   - Test Accuracy: {best_test_acc:.4f}")
    
    # ========== 5. ç¬¬äºŒé˜¶æ®µï¼šè¯¦ç»†è®­ç»ƒç›‘æŽ§ ==========
    print("\n" + "=" * 60)
    print("Phase 2: Detailed Training Monitoring".center(60))
    print("=" * 60)
    print(f"\nRe-training best model (n={best_n}) with monitoring enabled...")
    print("This will generate detailed training dynamics visualization.")
    
    # åˆ›å»ºç›‘æŽ§å™¨
    is_data_noisy = noise_ratio > 0
    monitor = BoostMonitor(
        noise_indices=noise_idx,
        clean_indices=clean_idx,
        is_data_noisy=is_data_noisy,
        checkpoint_interval=999,  # ä¸éœ€è¦checkpoint
        checkpoint_prefix="temp"
    )
    
    # ä½¿ç”¨ç›‘æŽ§å™¨è®­ç»ƒæœ€ä½³æ¨¡åž‹
    clf = AdaBoostClfWithMonitor(
        estimator=config["base_estimator"],
        n_estimators=best_n,
        learning_rate=config["learning_rate"],
        random_state=config["random_state"],
        monitor=monitor
    )
    
    print(f"Training with {best_n} estimators...")
    clf.fit(X_train, y_train)
    
    # è®°å½•éªŒè¯é›†æŒ‡æ ‡
    for i in range(best_n):
        train_acc = clf.score(X_train, y_train)
        test_acc = clf.score(X_test, y_test)
        # è¿™é‡Œç®€åŒ–äº†ï¼Œå®žé™…åº”è¯¥æ¯è½®è®°å½•
    
    print("âœ“ Training completed!")
    
    # ç”Ÿæˆè¯¦ç»†å¯è§†åŒ–
    print("\nGenerating detailed training visualization...")
    visualize_detailed_training(
        monitor=monitor,
        n_estimators=best_n,
        save_path=None  # è®¾ç½®è·¯å¾„å¯ä¿å­˜ï¼Œå¦‚ 'detailed_training.png'
    )
    
    # ========== 6. æ€»ç»“å’Œå»ºè®® ==========
    print("\n" + "=" * 60)
    print("Summary & Recommendations".center(60))
    print("=" * 60)
    
    final_overfit = results["overfitting_degree"][best_idx]
    
    print(f"\nðŸ“Š Model Performance:")
    print(f"   - Train Accuracy: {results['train_accuracy'][best_idx]:.4f}")
    print(f"   - Test Accuracy:  {results['test_accuracy'][best_idx]:.4f}")
    print(f"   - Overfitting:    {final_overfit:.4f} ({final_overfit*100:.2f}%)")
    
    # æ ¹æ®ç»“æžœç»™å‡ºå»ºè®®
    if final_overfit > 0.15:
        print("\nâš ï¸  Severe Overfitting Detected:")
        print(f"   - Consider reducing estimators")
        print(f"   - Try lower learning rate (e.g., 0.1)")
        print(f"   - Apply regularization techniques")
    elif final_overfit > 0.10:
        print("\nâš ï¸  Moderate Overfitting:")
        print(f"   - Current configuration is acceptable")
        print(f"   - Early stopping at n={best_n} recommended")
    else:
        print("\nâœ“ Good Model Fit:")
        print(f"   - Low overfitting degree")
        print(f"   - Model generalizes well")
    
    # å™ªå£°ç›¸å…³å»ºè®®
    if is_data_noisy:
        print(f"\nðŸ’¡ Noise-Specific Insights:")
        
        if len(monitor.noisy_weight_history) > 0:
            final_noisy_weight = monitor.noisy_weight_history[-1]
            final_clean_weight = monitor.clean_weight_history[-1]
            weight_ratio = final_noisy_weight / final_clean_weight if final_clean_weight > 0 else 0
            
            print(f"   - Final noisy sample weight: {final_noisy_weight:.4f}")
            print(f"   - Final clean sample weight: {final_clean_weight:.4f}")
            print(f"   - Weight ratio (noisy/clean): {weight_ratio:.3f}")
            
            if weight_ratio > 1.5:
                print(f"\n   âš ï¸  Noisy samples are over-weighted!")
                print(f"   - This indicates noise sensitivity")
                print(f"   - Consider robust AdaBoost methods")
    
    # Alpha ç³»æ•°åˆ†æž
    if len(monitor.alpha_history) > 0:
        avg_alpha = np.mean(monitor.alpha_history)
        std_alpha = np.std(monitor.alpha_history)
        print(f"\nðŸ“ˆ Weak Learner Analysis:")
        print(f"   - Average alpha: {avg_alpha:.3f}")
        print(f"   - Std of alpha:  {std_alpha:.3f}")
        
        if std_alpha / avg_alpha > 0.5:
            print(f"   - High variance in learner weights")
            print(f"   - Some learners much stronger than others")
    
    print("\n" + "=" * 60)
    print("\nâœ“ Visualization Complete!")
    print("\nðŸ’¡ Tips:")
    print("   - Two visualizations generated:")
    print("     1. Overfitting curves (Phase 1)")
    print("     2. Detailed training dynamics (Phase 2)")
    print("   - Set save_path to save figures")
    print("   - Adjust config for different experiments")
    print("=" * 60)


if __name__ == "__main__":
    main()



