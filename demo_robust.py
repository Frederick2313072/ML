"""
é²æ£’AdaBoostå¿«é€Ÿæ¼”ç¤º
å±•ç¤ºå¦‚ä½•ä½¿ç”¨é²æ£’æ–¹æ³•è§£å†³å™ªå£°å’Œè¿‡æ‹Ÿåˆé—®é¢˜
"""

from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from src.utils import prepare_data
from src.robust_adaboost import create_robust_adaboost


def quick_demo():
    """å¿«é€Ÿæ¼”ç¤º"""
    
    print("\n" + "â–ˆ" * 60)
    print("é²æ£’AdaBoostå¿«é€Ÿæ¼”ç¤º".center(56))
    print("â–ˆ" * 60)
    
    # å‡†å¤‡å«å™ªå£°çš„æ•°æ®
    print("\nå‡†å¤‡æ•°æ®ï¼ˆ5%æ ‡ç­¾å™ªå£°ï¼‰...")
    X_train, X_test, y_train, y_test, noise_idx, clean_idx = prepare_data(
        noise_ratio=0.05
    )
    
    print(f"è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
    print(f"æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
    print(f"å™ªå£°æ ·æœ¬: {len(noise_idx)} ({len(noise_idx)/len(X_train)*100:.1f}%)")
    
    # ========== 1. æ ‡å‡†AdaBoost ==========
    print("\n" + "=" * 60)
    print("1. æ ‡å‡†AdaBoostï¼ˆåŸºå‡†ï¼‰")
    print("=" * 60)
    
    clf_standard = AdaBoostClassifier(
        estimator=DecisionTreeClassifier(max_depth=1),
        n_estimators=50,
        learning_rate=0.5,
        random_state=42
    )
    
    clf_standard.fit(X_train, y_train)
    
    train_acc_std = clf_standard.score(X_train, y_train)
    test_acc_std = clf_standard.score(X_test, y_test)
    overfit_std = train_acc_std - test_acc_std
    
    print(f"è®­ç»ƒé›†å‡†ç¡®ç‡: {train_acc_std:.4f} ({train_acc_std*100:.2f}%)")
    print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {test_acc_std:.4f} ({test_acc_std*100:.2f}%)")
    print(f"è¿‡æ‹Ÿåˆç¨‹åº¦: {overfit_std:.4f} ({overfit_std*100:.2f}%)")
    
    # å™ªå£°æ ·æœ¬åˆ†æ
    y_pred_std = clf_standard.predict(X_train)
    noise_acc_std = (y_train[noise_idx] == y_pred_std[noise_idx]).mean()
    clean_acc_std = (y_train[clean_idx] == y_pred_std[clean_idx]).mean()
    
    print(f"å™ªå£°æ ·æœ¬å‡†ç¡®ç‡: {noise_acc_std:.4f}")
    print(f"å¹²å‡€æ ·æœ¬å‡†ç¡®ç‡: {clean_acc_std:.4f}")
    print(f"å‡†ç¡®ç‡å·®è·: {clean_acc_std - noise_acc_std:.4f}")
    
    # ========== 2. é²æ£’AdaBoostï¼ˆå¹³è¡¡é…ç½®ï¼‰==========
    print("\n" + "=" * 60)
    print("2. é²æ£’AdaBoost - å¹³è¡¡é…ç½®")
    print("=" * 60)
    print("æ”¹è¿›ç­–ç•¥: æƒé‡è£å‰ª + æ—©åœ")
    
    clf_robust = create_robust_adaboost(strategy="balanced", random_state=42)
    clf_robust.fit(X_train, y_train)
    
    train_acc_rob = clf_robust.score(X_train, y_train)
    test_acc_rob = clf_robust.score(X_test, y_test)
    overfit_rob = train_acc_rob - test_acc_rob
    
    print(f"\nç»“æœ:")
    print(f"è®­ç»ƒé›†å‡†ç¡®ç‡: {train_acc_rob:.4f} ({train_acc_rob*100:.2f}%)")
    print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {test_acc_rob:.4f} ({test_acc_rob*100:.2f}%)")
    print(f"è¿‡æ‹Ÿåˆç¨‹åº¦: {overfit_rob:.4f} ({overfit_rob*100:.2f}%)")
    print(f"ä½¿ç”¨å¼±å­¦ä¹ å™¨: {clf_robust.best_n_estimators_}/{clf_robust.n_estimators}")
    
    # å™ªå£°æ ·æœ¬åˆ†æ
    y_pred_rob = clf_robust.predict(X_train)
    noise_acc_rob = (y_train[noise_idx] == y_pred_rob[noise_idx]).mean()
    clean_acc_rob = (y_train[clean_idx] == y_pred_rob[clean_idx]).mean()
    
    print(f"å™ªå£°æ ·æœ¬å‡†ç¡®ç‡: {noise_acc_rob:.4f}")
    print(f"å¹²å‡€æ ·æœ¬å‡†ç¡®ç‡: {clean_acc_rob:.4f}")
    print(f"å‡†ç¡®ç‡å·®è·: {clean_acc_rob - noise_acc_rob:.4f}")
    
    # ========== 3. æ”¹è¿›æ•ˆæœå¯¹æ¯” ==========
    print("\n" + "â–ˆ" * 60)
    print("æ”¹è¿›æ•ˆæœå¯¹æ¯”".center(56))
    print("â–ˆ" * 60)
    
    test_improve = test_acc_rob - test_acc_std
    overfit_improve = overfit_std - overfit_rob
    noise_gap_improve = (clean_acc_std - noise_acc_std) - (clean_acc_rob - noise_acc_rob)
    
    print(f"\nç›¸æ¯”æ ‡å‡†AdaBoost:")
    print(f"  æµ‹è¯•å‡†ç¡®ç‡æå‡: {test_improve:+.4f} ({test_improve*100:+.2f}%)")
    print(f"  è¿‡æ‹Ÿåˆå‡å°‘: {overfit_improve:+.4f} ({overfit_improve*100:+.2f}%)")
    print(f"  å™ªå£°å·®è·ç¼©å°: {noise_gap_improve:+.4f} ({noise_gap_improve*100:+.2f}%)")
    
    # ========== 4. ç»“è®º ==========
    print("\n" + "=" * 60)
    print("ç»“è®º".center(56))
    print("=" * 60)
    
    if test_improve > 0:
        print("\nâœ… æµ‹è¯•å‡†ç¡®ç‡æ˜¾è‘—æå‡")
    
    if overfit_improve > 0.02:
        print("âœ… è¿‡æ‹Ÿåˆæ˜¾è‘—å‡å°‘")
    
    if noise_gap_improve > 0:
        print("âœ… å™ªå£°é²æ£’æ€§æå‡")
    
    print(f"\nğŸ’¡ æ¨è:")
    print(f"   - å¯¹äºå«å™ªå£°æ•°æ®ï¼Œä½¿ç”¨é²æ£’AdaBoost")
    print(f"   - è‡ªåŠ¨æ—©åœæ‰¾åˆ°æœ€ä½³å¼±å­¦ä¹ å™¨æ•°é‡ (n={clf_robust.best_n_estimators_})")
    print(f"   - æƒé‡è£å‰ªé˜²æ­¢å™ªå£°æ ·æœ¬æƒé‡çˆ†ç‚¸")
    
    print("\n" + "=" * 60)
    print("\nâœ“ æ¼”ç¤ºå®Œæˆï¼")
    print("\næ›´å¤šé…ç½®è¯·æŸ¥çœ‹: docs/robust_adaboost_guide.md")
    print("å®Œæ•´å¯¹æ¯”è¯·è¿è¡Œ: python compare_robust_methods.py")
    print("=" * 60)


if __name__ == "__main__":
    quick_demo()


