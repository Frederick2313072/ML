"""
å¯è§†åŒ–AdaBoostè¿‡æ‹Ÿåˆè¿‡ç¨‹
ç®€æ´çš„è„šæœ¬ï¼Œå±•ç¤ºæ¨¡å‹éšç€å¼±å­¦ä¹ å™¨æ•°é‡å¢åŠ çš„è¿‡æ‹Ÿåˆè¡Œä¸º
"""

from sklearn.tree import DecisionTreeClassifier
from src.utils import prepare_data
from src.evaluation import visualize_overfitting_process


def main():
    """ä¸»å‡½æ•°ï¼šå¯è§†åŒ–è¿‡æ‹Ÿåˆè¿‡ç¨‹"""

    print("\n" + "â–ˆ" * 60)
    print("AdaBoost è¿‡æ‹Ÿåˆå¯è§†åŒ–".center(56))
    print("â–ˆ" * 60)

    # ========== 1. é€‰æ‹©æ•°æ®ç±»å‹ ==========
    print("\né€‰æ‹©æ•°æ®ç±»å‹:")
    print("1. å¹²å‡€æ•°æ®ï¼ˆæ— å™ªå£°ï¼‰")
    print("2. å«å™ªå£°æ•°æ®ï¼ˆ5%å™ªå£°ï¼‰")
    print("3. å«å™ªå£°æ•°æ®ï¼ˆ10%å™ªå£°ï¼‰")

    # é»˜è®¤ä½¿ç”¨é€‰é¡¹2
    choice = 2  # å¯ä»¥ä¿®æ”¹ä¸º1æˆ–3

    if choice == 1:
        noise_ratio = 0
        data_type = "å¹²å‡€æ•°æ®"
    elif choice == 2:
        noise_ratio = 0.05
        data_type = "5%å™ªå£°æ•°æ®"
    else:
        noise_ratio = 0.10
        data_type = "10%å™ªå£°æ•°æ®"

    print(f"\nä½¿ç”¨: {data_type}")
    print("-" * 60)

    # ========== 2. å‡†å¤‡æ•°æ® ==========
    print("\nå‡†å¤‡æ•°æ®...")
    X_train, X_test, y_train, y_test, _, _ = prepare_data(noise_ratio=noise_ratio)

    print(f"è®­ç»ƒé›†å¤§å°: {len(X_train)}")
    print(f"æµ‹è¯•é›†å¤§å°: {len(X_test)}")

    # ========== 3. é€‰æ‹©é…ç½® ==========
    print("\n" + "=" * 60)
    print("é…ç½®é€‰é¡¹".center(56))
    print("=" * 60)

    # é…ç½®1: å¿«é€Ÿæµ‹è¯•ï¼ˆæ¨èï¼‰
    config = {
        "base_estimator": DecisionTreeClassifier(max_depth=1),  # å†³ç­–æ ‘æ¡©
        "n_estimators_list": [1, 5, 10, 20, 30, 40, 50, 75, 100],  # æµ‹è¯•ç‚¹
        "learning_rate": 0.5,  # å­¦ä¹ ç‡
        "random_state": 42,
    }

    # é…ç½®2: ç²¾ç»†åˆ†æï¼ˆæ›´å¤šæµ‹è¯•ç‚¹ï¼Œéœ€è¦æ›´é•¿æ—¶é—´ï¼‰
    # config = {
    #     "base_estimator": DecisionTreeClassifier(max_depth=1),
    #     "n_estimators_list": list(range(1, 101, 5)),  # [1, 6, 11, ..., 96]
    #     "learning_rate": 0.5,
    #     "random_state": 42,
    # }

    # é…ç½®3: æ·±æ ‘æµ‹è¯•ï¼ˆè§‚å¯Ÿæ›´å¤æ‚åŸºå­¦ä¹ å™¨çš„å½±å“ï¼‰
    # config = {
    #     "base_estimator": DecisionTreeClassifier(max_depth=3),
    #     "n_estimators_list": [1, 5, 10, 20, 30, 40, 50],
    #     "learning_rate": 0.5,
    #     "random_state": 42,
    # }

    print(f"åŸºå­¦ä¹ å™¨: å†³ç­–æ ‘ (max_depth={config['base_estimator'].max_depth})")
    print(f"æµ‹è¯•ç‚¹æ•°é‡: {len(config['n_estimators_list'])}")
    print(f"å¼±å­¦ä¹ å™¨èŒƒå›´: {config['n_estimators_list'][0]} - {config['n_estimators_list'][-1]}")
    print(f"å­¦ä¹ ç‡: {config['learning_rate']}")

    # ========== 4. å¯è§†åŒ–è¿‡æ‹Ÿåˆ ==========
    print("\nå¼€å§‹è®­ç»ƒå’Œå¯è§†åŒ–...")
    print("-" * 60)

    results = visualize_overfitting_process(
        X_train,
        y_train,
        X_test,
        y_test,
        base_estimator=config["base_estimator"],
        n_estimators_list=config["n_estimators_list"],
        learning_rate=config["learning_rate"],
        random_state=config["random_state"],
        save_path=None,  # è®¾ä¸ºè·¯å¾„å¯ä¿å­˜å›¾è¡¨ï¼Œå¦‚ 'overfitting.png'
    )

    # ========== 5. é¢å¤–åˆ†æï¼ˆå¯é€‰ï¼‰ ==========
    print("\n" + "=" * 60)
    print("å»ºè®®".center(56))
    print("=" * 60)

    best_idx = results["test_accuracy"].index(max(results["test_accuracy"]))
    best_n = results["n_estimators"][best_idx]
    final_n = results["n_estimators"][-1]
    final_overfit = results["overfitting_degree"][-1]

    # æ ¹æ®ç»“æœç»™å‡ºå»ºè®®
    if final_overfit > 0.15:
        print("\nâš ï¸  ä¸¥é‡è¿‡æ‹Ÿåˆè­¦å‘Š:")
        print(f"   - å½“å‰è¿‡æ‹Ÿåˆç¨‹åº¦: {final_overfit:.2%}")
        print(f"   - å»ºè®®å‡å°‘å¼±å­¦ä¹ å™¨æ•°é‡è‡³ {best_n} å·¦å³")
        print(f"   - æˆ–ä½¿ç”¨æ›´å°çš„å­¦ä¹ ç‡ï¼ˆå¦‚ 0.1ï¼‰")
    elif final_overfit > 0.10:
        print("\nâš ï¸  ä¸­åº¦è¿‡æ‹Ÿåˆ:")
        print(f"   - å½“å‰è¿‡æ‹Ÿåˆç¨‹åº¦: {final_overfit:.2%}")
        print(f"   - å»ºè®®ä½¿ç”¨æ—©åœï¼Œåœ¨ n={best_n} å¤„åœæ­¢è®­ç»ƒ")
    elif final_overfit < 0.05:
        print("\nâœ“ æ¨¡å‹æ‹Ÿåˆè‰¯å¥½:")
        print(f"   - è¿‡æ‹Ÿåˆç¨‹åº¦ä½: {final_overfit:.2%}")
        print(f"   - å¯ä»¥è€ƒè™‘å¢åŠ å¼±å­¦ä¹ å™¨æ•°é‡ä»¥æå‡æ€§èƒ½")
    else:
        print("\nâœ“ æ¨¡å‹è¡¨ç°è‰¯å¥½:")
        print(f"   - è¿‡æ‹Ÿåˆç¨‹åº¦: {final_overfit:.2%} (å¯æ¥å—)")
        print(f"   - å»ºè®®ä½¿ç”¨ n={best_n} ä¸ªå¼±å­¦ä¹ å™¨")

    # å™ªå£°æ•°æ®çš„é¢å¤–å»ºè®®
    if noise_ratio > 0:
        print(f"\nğŸ’¡ å™ªå£°æ•°æ®å»ºè®®:")
        print(f"   - å½“å‰æ•°æ®æœ‰ {noise_ratio*100:.0f}% å™ªå£°")
        print(f"   - AdaBoost å¯¹å™ªå£°æ•æ„Ÿï¼Œå®¹æ˜“è¿‡æ‹Ÿåˆ")
        print(f"   - å»ºè®®:")
        print(f"     1. ä½¿ç”¨è¾ƒå°‘çš„å¼±å­¦ä¹ å™¨ï¼ˆ{best_n} å·¦å³ï¼‰")
        print(f"     2. é™ä½å­¦ä¹ ç‡ï¼ˆä» 0.5 åˆ° 0.3ï¼‰")
        print(f"     3. è€ƒè™‘æ•°æ®æ¸…æ´—æˆ–å™ªå£°é²æ£’æ–¹æ³•")

    print("\n" + "=" * 60)
    print("\nâœ“ å¯è§†åŒ–å®Œæˆï¼")
    print("\nğŸ’¡ æç¤º:")
    print("   - å›¾è¡¨ä¼šè‡ªåŠ¨æ˜¾ç¤ºï¼ˆå…³é—­çª—å£ç»§ç»­ï¼‰")
    print("   - è¦ä¿å­˜å›¾è¡¨ï¼Œè®¾ç½® save_path='overfitting.png'")
    print("   - è¦æµ‹è¯•ä¸åŒé…ç½®ï¼Œä¿®æ”¹è„šæœ¬ä¸­çš„ config å­—å…¸")
    print("=" * 60)


if __name__ == "__main__":
    main()

