"""
å¯¹æ¯”æ ‡å‡†AdaBoostå’Œé²æ£’æ–¹æ³•
æ¸…æ¥šå±•ç¤ºæ”¹è¿›æ•ˆæœ
"""

import numpy as np
import matplotlib.pyplot as plt
import matplotlib
from mplfonts.bin.cli import init
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
import time

from src.utils import prepare_data
from src.robust_adaboost import RobustAdaBoost, create_robust_adaboost

# åˆå§‹åŒ–ä¸­æ–‡å­—ä½“
init()
matplotlib.rcParams["font.family"] = "Source Han Sans CN"
matplotlib.rcParams["axes.unicode_minus"] = False


def train_and_evaluate(clf, X_train, y_train, X_test, y_test, name):
    """
    è®­ç»ƒå¹¶è¯„ä¼°æ¨¡å‹

    Parameters
    ----------
    clf : åˆ†ç±»å™¨
    X_train, y_train : è®­ç»ƒé›†
    X_test, y_test : æµ‹è¯•é›†
    name : æ¨¡å‹åç§°

    Returns
    -------
    ç»“æœå­—å…¸
    """
    print(f"\n{'='*60}")
    print(f"è®­ç»ƒ: {name}")
    print(f"{'='*60}")

    # è®­ç»ƒ
    start_time = time.time()
    clf.fit(X_train, y_train)
    train_time = time.time() - start_time

    # è¯„ä¼°
    train_acc = clf.score(X_train, y_train)
    test_acc = clf.score(X_test, y_test)
    overfit = train_acc - test_acc

    # è·å–å®é™…ä½¿ç”¨çš„å¼±å­¦ä¹ å™¨æ•°é‡
    if hasattr(clf, "best_n_estimators_"):
        n_used = clf.best_n_estimators_
    elif hasattr(clf, "n_estimators_"):
        n_used = clf.n_estimators_
    else:
        n_used = clf.n_estimators

    print(f"è®­ç»ƒæ—¶é—´: {train_time:.2f} ç§’")
    print(f"ä½¿ç”¨å¼±å­¦ä¹ å™¨æ•°é‡: {n_used}")
    print(f"è®­ç»ƒé›†å‡†ç¡®ç‡: {train_acc:.4f} ({train_acc*100:.2f}%)")
    print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {test_acc:.4f} ({test_acc*100:.2f}%)")
    print(f"è¿‡æ‹Ÿåˆç¨‹åº¦: {overfit:.4f} ({overfit*100:.2f}%)")

    return {
        "name": name,
        "train_acc": train_acc,
        "test_acc": test_acc,
        "overfit": overfit,
        "train_time": train_time,
        "n_used": n_used,
        "model": clf,
    }


def compare_on_noisy_samples(results, X_train, y_train, noise_idx, clean_idx):
    """
    å¯¹æ¯”åœ¨å™ªå£°æ ·æœ¬ä¸Šçš„è¡¨ç°

    Parameters
    ----------
    results : ç»“æœåˆ—è¡¨
    X_train, y_train : è®­ç»ƒé›†
    noise_idx : å™ªå£°æ ·æœ¬ç´¢å¼•
    clean_idx : å¹²å‡€æ ·æœ¬ç´¢å¼•
    """
    if len(noise_idx) == 0:
        print("\næ— å™ªå£°æ ·æœ¬ï¼Œè·³è¿‡å™ªå£°åˆ†æ")
        return

    print("\n" + "=" * 60)
    print("å™ªå£°æ ·æœ¬åˆ†æ".center(56))
    print("=" * 60)

    for result in results:
        clf = result["model"]
        y_pred = clf.predict(X_train)

        # å™ªå£°æ ·æœ¬å‡†ç¡®ç‡
        noise_acc = accuracy_score(y_train[noise_idx], y_pred[noise_idx])

        # å¹²å‡€æ ·æœ¬å‡†ç¡®ç‡
        clean_acc = accuracy_score(y_train[clean_idx], y_pred[clean_idx])

        # å·®è·
        gap = clean_acc - noise_acc

        print(f"\n{result['name']}:")
        print(f"  å™ªå£°æ ·æœ¬å‡†ç¡®ç‡: {noise_acc:.4f} ({noise_acc*100:.2f}%)")
        print(f"  å¹²å‡€æ ·æœ¬å‡†ç¡®ç‡: {clean_acc:.4f} ({clean_acc*100:.2f}%)")
        print(f"  å‡†ç¡®ç‡å·®è·: {gap:.4f} ({gap*100:.2f}%)")

        result["noise_acc"] = noise_acc
        result["clean_acc"] = clean_acc
        result["noise_gap"] = gap


def plot_comparison(results, save_path=None):
    """
    å¯è§†åŒ–å¯¹æ¯”ç»“æœ

    Parameters
    ----------
    results : ç»“æœåˆ—è¡¨
    save_path : ä¿å­˜è·¯å¾„
    """
    n_models = len(results)
    names = [r["name"] for r in results]

    # åˆ›å»ºå›¾å½¢
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))

    # å­å›¾1: è®­ç»ƒ vs æµ‹è¯•å‡†ç¡®ç‡
    ax1 = axes[0, 0]
    x = np.arange(n_models)
    width = 0.35

    train_accs = [r["train_acc"] for r in results]
    test_accs = [r["test_acc"] for r in results]

    ax1.bar(x - width / 2, train_accs, width, label="è®­ç»ƒé›†", color="skyblue")
    ax1.bar(x + width / 2, test_accs, width, label="æµ‹è¯•é›†", color="lightcoral")

    ax1.set_ylabel("å‡†ç¡®ç‡", fontsize=12)
    ax1.set_title("è®­ç»ƒé›† vs æµ‹è¯•é›†å‡†ç¡®ç‡", fontsize=14)
    ax1.set_xticks(x)
    ax1.set_xticklabels(names, rotation=15, ha="right")
    ax1.legend()
    ax1.grid(axis="y", alpha=0.3)
    ax1.set_ylim([0.5, 1.0])

    # å­å›¾2: è¿‡æ‹Ÿåˆç¨‹åº¦
    ax2 = axes[0, 1]
    overfits = [r["overfit"] for r in results]
    colors = ["red" if o > 0.15 else "orange" if o > 0.10 else "green" for o in overfits]

    bars = ax2.bar(x, overfits, color=colors, alpha=0.7)
    ax2.axhline(y=0.10, color="orange", linestyle="--", linewidth=1, label="é˜ˆå€¼:10%")
    ax2.axhline(y=0.15, color="red", linestyle="--", linewidth=1, label="é˜ˆå€¼:15%")

    ax2.set_ylabel("è¿‡æ‹Ÿåˆç¨‹åº¦", fontsize=12)
    ax2.set_title("è¿‡æ‹Ÿåˆç¨‹åº¦å¯¹æ¯”", fontsize=14)
    ax2.set_xticks(x)
    ax2.set_xticklabels(names, rotation=15, ha="right")
    ax2.legend()
    ax2.grid(axis="y", alpha=0.3)

    # å­å›¾3: å™ªå£° vs å¹²å‡€æ ·æœ¬å‡†ç¡®ç‡ï¼ˆå¦‚æœæœ‰ï¼‰
    ax3 = axes[1, 0]
    if "noise_acc" in results[0]:
        noise_accs = [r["noise_acc"] for r in results]
        clean_accs = [r["clean_acc"] for r in results]

        ax3.bar(x - width / 2, noise_accs, width, label="å™ªå£°æ ·æœ¬", color="salmon")
        ax3.bar(x + width / 2, clean_accs, width, label="å¹²å‡€æ ·æœ¬", color="lightgreen")

        ax3.set_ylabel("å‡†ç¡®ç‡", fontsize=12)
        ax3.set_title("å™ªå£°æ ·æœ¬ vs å¹²å‡€æ ·æœ¬å‡†ç¡®ç‡", fontsize=14)
        ax3.set_xticks(x)
        ax3.set_xticklabels(names, rotation=15, ha="right")
        ax3.legend()
        ax3.grid(axis="y", alpha=0.3)
    else:
        ax3.text(
            0.5,
            0.5,
            "æ— å™ªå£°æ•°æ®",
            ha="center",
            va="center",
            fontsize=14,
            transform=ax3.transAxes,
        )
        ax3.set_xticks([])
        ax3.set_yticks([])

    # å­å›¾4: è®­ç»ƒæ—¶é—´å’Œå¼±å­¦ä¹ å™¨æ•°é‡
    ax4 = axes[1, 1]
    train_times = [r["train_time"] for r in results]
    n_used_list = [r["n_used"] for r in results]

    ax4_twin = ax4.twinx()

    bars1 = ax4.bar(
        x - width / 2, train_times, width, label="è®­ç»ƒæ—¶é—´(ç§’)", color="steelblue"
    )
    bars2 = ax4_twin.bar(
        x + width / 2, n_used_list, width, label="å¼±å­¦ä¹ å™¨æ•°é‡", color="darkorange"
    )

    ax4.set_ylabel("è®­ç»ƒæ—¶é—´ (ç§’)", fontsize=12, color="steelblue")
    ax4_twin.set_ylabel("å¼±å­¦ä¹ å™¨æ•°é‡", fontsize=12, color="darkorange")
    ax4.set_title("è®­ç»ƒæ•ˆç‡å¯¹æ¯”", fontsize=14)
    ax4.set_xticks(x)
    ax4.set_xticklabels(names, rotation=15, ha="right")

    # åˆå¹¶å›¾ä¾‹
    lines1, labels1 = ax4.get_legend_handles_labels()
    lines2, labels2 = ax4_twin.get_legend_handles_labels()
    ax4.legend(lines1 + lines2, labels1 + labels2, loc="upper left")

    ax4.grid(axis="y", alpha=0.3)

    plt.suptitle("AdaBoost æ–¹æ³•å¯¹æ¯”", fontsize=16, y=0.995)
    plt.tight_layout()

    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches="tight")
        print(f"\nå¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {save_path}")
    else:
        plt.show()

    plt.close()


def print_summary(results):
    """
    æ‰“å°æ€»ç»“æŠ¥å‘Š

    Parameters
    ----------
    results : ç»“æœåˆ—è¡¨
    """
    print("\n" + "â–ˆ" * 60)
    print("å¯¹æ¯”æ€»ç»“".center(56))
    print("â–ˆ" * 60)

    # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
    best_test = max(results, key=lambda x: x["test_acc"])
    best_overfit = min(results, key=lambda x: x["overfit"])

    print(f"\nğŸ† æœ€ä½³æµ‹è¯•å‡†ç¡®ç‡:")
    print(f"   {best_test['name']}: {best_test['test_acc']:.4f}")

    print(f"\nâœ“ æœ€å°è¿‡æ‹Ÿåˆ:")
    print(f"   {best_overfit['name']}: {best_overfit['overfit']:.4f}")

    if "noise_gap" in results[0]:
        best_noise = min(results, key=lambda x: x["noise_gap"])
        print(f"\nğŸ’¡ æœ€ä½³å™ªå£°é²æ£’æ€§:")
        print(
            f"   {best_noise['name']}: å™ªå£°å·®è· = {best_noise['noise_gap']:.4f}"
        )

    # æ”¹è¿›å¹…åº¦
    standard = next((r for r in results if "æ ‡å‡†" in r["name"]), None)
    if standard:
        print(f"\nğŸ“ˆ ç›¸æ¯”æ ‡å‡†AdaBoostçš„æ”¹è¿›:")
        for result in results:
            if result["name"] == standard["name"]:
                continue

            test_improve = result["test_acc"] - standard["test_acc"]
            overfit_improve = standard["overfit"] - result["overfit"]

            print(f"\n   {result['name']}:")
            print(
                f"     æµ‹è¯•å‡†ç¡®ç‡: {test_improve:+.4f} ({test_improve*100:+.2f}%)"
            )
            print(
                f"     è¿‡æ‹Ÿåˆå‡å°‘: {overfit_improve:+.4f} ({overfit_improve*100:+.2f}%)"
            )

    print("\n" + "=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "â–ˆ" * 60)
    print("AdaBoost é²æ£’æ–¹æ³•å¯¹æ¯”å®éªŒ".center(56))
    print("â–ˆ" * 60)

    # ========== 1. å‡†å¤‡æ•°æ® ==========
    print("\næ­¥éª¤1: å‡†å¤‡æ•°æ®")
    print("-" * 60)

    # ä½¿ç”¨å«å™ªå£°çš„æ•°æ®ï¼ˆæ›´èƒ½ä½“ç°æ”¹è¿›æ•ˆæœï¼‰
    noise_ratio = 0.05  # å¯ä»¥æ”¹ä¸º 0.10 æµ‹è¯•æ›´é«˜å™ªå£°
    X_train, X_test, y_train, y_test, noise_idx, clean_idx = prepare_data(
        noise_ratio=noise_ratio
    )

    print(f"æ•°æ®é›†: MNIST")
    print(f"å™ªå£°æ¯”ä¾‹: {noise_ratio*100:.0f}%")
    print(f"è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
    print(f"æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
    print(f"å™ªå£°æ ·æœ¬: {len(noise_idx)}")

    # ========== 2. å®šä¹‰è¦å¯¹æ¯”çš„æ¨¡å‹ ==========
    print("\næ­¥éª¤2: å‡†å¤‡å¯¹æ¯”æ¨¡å‹")
    print("-" * 60)

    base = DecisionTreeClassifier(max_depth=1)

    models = [
        # æ ‡å‡†AdaBoostï¼ˆåŸºå‡†ï¼‰
        (
            AdaBoostClassifier(
                estimator=base, n_estimators=50, learning_rate=0.5, random_state=42
            ),
            "æ ‡å‡†AdaBoost",
        ),
        # é²æ£’æ–¹æ³•1: å¹³è¡¡é…ç½®
        (create_robust_adaboost("balanced", random_state=42), "é²æ£’-å¹³è¡¡"),
        # é²æ£’æ–¹æ³•2: æ¿€è¿›è£å‰ªï¼ˆæœ€é€‚åˆé«˜å™ªå£°ï¼‰
        (create_robust_adaboost("aggressive_clip", random_state=42), "é²æ£’-æ¿€è¿›è£å‰ª"),
        # é²æ£’æ–¹æ³•3: é‡ç‚¹æ—©åœ
        (create_robust_adaboost("early_stop", random_state=42), "é²æ£’-æ—©åœ"),
    ]

    print(f"å¯¹æ¯”æ¨¡å‹æ•°é‡: {len(models)}")
    for _, name in models:
        print(f"  - {name}")

    # ========== 3. è®­ç»ƒå’Œè¯„ä¼° ==========
    print("\næ­¥éª¤3: è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹")
    print("-" * 60)

    results = []
    for clf, name in models:
        result = train_and_evaluate(clf, X_train, y_train, X_test, y_test, name)
        results.append(result)

    # ========== 4. å™ªå£°æ ·æœ¬åˆ†æ ==========
    compare_on_noisy_samples(results, X_train, y_train, noise_idx, clean_idx)

    # ========== 5. å¯è§†åŒ–å¯¹æ¯” ==========
    print("\næ­¥éª¤4: ç”Ÿæˆå¯¹æ¯”å¯è§†åŒ–")
    print("-" * 60)
    plot_comparison(results, save_path="results/robust_comparison.png")

    # ========== 6. æ‰“å°æ€»ç»“ ==========
    print_summary(results)

    # ========== 7. å»ºè®® ==========
    print("\nğŸ’¡ å»ºè®®:")
    best_result = max(results, key=lambda x: x["test_acc"])

    if best_result["overfit"] < 0.10:
        print(f"   âœ… æ¨èä½¿ç”¨: {best_result['name']}")
        print(f"      - æµ‹è¯•å‡†ç¡®ç‡æœ€é«˜: {best_result['test_acc']:.4f}")
        print(f"      - è¿‡æ‹Ÿåˆç¨‹åº¦ä½: {best_result['overfit']:.4f}")
    elif best_result["overfit"] < 0.15:
        print(f"   âš ï¸ å¯ä»¥ä½¿ç”¨: {best_result['name']}")
        print(f"      - æµ‹è¯•å‡†ç¡®ç‡: {best_result['test_acc']:.4f}")
        print(f"      - è¿‡æ‹Ÿåˆç¨‹åº¦ä¸­ç­‰: {best_result['overfit']:.4f}")
        print(f"      - å»ºè®®è¿›ä¸€æ­¥è°ƒæ•´å‚æ•°")
    else:
        print(f"   âš ï¸ {best_result['name']} ä»æœ‰æ˜æ˜¾è¿‡æ‹Ÿåˆ")
        print(f"      - å»ºè®®ä½¿ç”¨'æ¿€è¿›è£å‰ª'æˆ–'ä¿å®ˆ'é…ç½®")
        print(f"      - æˆ–é™ä½å­¦ä¹ ç‡åˆ° 0.1-0.3")

    if noise_ratio > 0:
        print(f"\n   ğŸ’¡ å™ªå£°æ•°æ®å»ºè®®:")
        print(f"      - å½“å‰å™ªå£°: {noise_ratio*100:.0f}%")
        if noise_ratio >= 0.1:
            print(f"      - æ¨èä½¿ç”¨: 'é²æ£’-æ¿€è¿›è£å‰ª' æˆ– 'ä¿å®ˆ' é…ç½®")
        else:
            print(f"      - æ¨èä½¿ç”¨: 'é²æ£’-å¹³è¡¡' é…ç½®")

    print("\n" + "=" * 60)
    print("\nâœ“ å¯¹æ¯”å®éªŒå®Œæˆï¼")


if __name__ == "__main__":
    main()

