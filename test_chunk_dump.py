import joblib
import lzma
import hashlib
import numpy as np

from src.utils import load_compressed, dump_compressed_chunks, load_compressed_chunks


def file_md5(path):
    md5 = hashlib.md5()
    with open(path, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            md5.update(chunk)
    return md5.hexdigest()


def verify_behavior(original, recovered, name="obj"):
    """
    éªŒè¯å¯¹è±¡çš„è¡Œä¸ºä¸€è‡´æ€§ï¼š
    - å¯¹æœ‰ predict() æ–¹æ³•çš„æ¨¡å‹ï¼šéªŒè¯é¢„æµ‹ç»“æœä¸€è‡´
    - å¯¹ monitorï¼šéªŒè¯å…³é”®å±æ€§æ›²çº¿ä¸€è‡´
    """
    ok = True

    # â‘  é¢„æµ‹ä¸€è‡´æ€§ï¼ˆé€‚ç”¨äºæ¨¡å‹ï¼‰
    if hasattr(original, "predict"):
        X = np.random.randn(128, getattr(original, "n_features_in_", 4))
        y1 = original.predict(X)
        y2 = recovered.predict(X)
        if np.array_equal(y1, y2):
            print(f"[OK] {name} é¢„æµ‹è¡Œä¸ºä¸€è‡´")
        else:
            print(f"[ERR] {name} é¢„æµ‹è¡Œä¸ºä¸ä¸€è‡´")
            ok = False

    # â‘¡ ç›‘æ§å™¨è¡Œä¸ºä¸€è‡´æ€§
    # ä¾‹å¦‚ Monitor().loss_curve, weights_history ç­‰
    for k, v in original.__dict__.items():
        if isinstance(v, np.ndarray):
            if not np.array_equal(v, recovered.__dict__.get(k)):
                print(f"[ERR] Monitor æ•°ç»„å­—æ®µ {k} ä¸ä¸€è‡´")
                ok = False

        elif isinstance(v, list) and all(isinstance(x, (int, float)) for x in v):
            if v != recovered.__dict__.get(k):
                print(f"[ERR] Monitor åˆ—è¡¨å­—æ®µ {k} ä¸ä¸€è‡´")
                ok = False

    if ok:
        print(f"[OK] {name} è¡Œä¸ºä¸€è‡´")

    return ok


def verify_md5(original_path, merged_path, name="obj"):
    md5_orig = file_md5(original_path)
    md5_merged = file_md5(merged_path)

    if md5_orig == md5_merged:
        print(f"[OK] {name} äºŒè¿›åˆ¶å®Œå…¨ä¸€è‡´ï¼ˆæœ€é«˜ç­‰çº§éªŒè¯ï¼‰")
        return True
    else:
        print(f"[ERR] {name} äºŒè¿›åˆ¶ä¸ä¸€è‡´")
        return False


def verify_chunk_correctness(original_path, chunks_loader_func, name="obj"):
    print(f"\n===== æ ¡éªŒ {name} =====")

    # åŠ è½½åŸå§‹å¯¹è±¡
    with lzma.open(original_path, "rb") as f:
        original = joblib.load(f)

    # åŠ è½½åˆ†ç‰‡æ¢å¤å¯¹è±¡
    recovered = chunks_loader_func(original_path)

    # è·å– merged è·¯å¾„
    merged_path = original_path + ".merged"

    ok_md5 = verify_md5(original_path, merged_path, name=name)
    ok_behavior = verify_behavior(original, recovered, name=name)

    return ok_md5 and ok_behavior


if __name__ == "__main__":
    clf_path = "./experiments/baseline_est500_depth2/results/model.joblib.xz"
    monitor_path = "./experiments/baseline_est500_depth2/results/monitor.joblib.xz"

    # å…ˆåˆ‡ç‰‡
    # dump_compressed_chunks(load_compressed(clf_path), clf_path[:-3])  # å»æ‰ .xz
    # dump_compressed_chunks(load_compressed(monitor_path), monitor_path[:-3])

    # æ ¡éªŒæ¨¡å‹
    ok_clf = verify_chunk_correctness(
        clf_path, lambda p: load_compressed_chunks(p), name="Classifier"
    )

    # æ ¡éªŒç›‘æ§å™¨
    ok_monitor = verify_chunk_correctness(
        monitor_path, lambda p: load_compressed_chunks(p), name="Monitor"
    )

    if ok_clf and ok_monitor:
        print("ğŸ‰ æ‰€æœ‰æ ¡éªŒå‡é€šè¿‡ï¼åˆ†ç‰‡åçš„å¯¹è±¡ä¸åŸå§‹å¯¹è±¡å®Œå…¨ä¸€è‡´ã€‚")
    else:
        print("âŒ æ ¡éªŒæœªé€šè¿‡ï¼Œè¯·æ£€æŸ¥åˆ†ç‰‡å’Œåˆå¹¶æµç¨‹ï¼")
